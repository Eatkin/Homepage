import os
import json
import re
from datetime import datetime
from bs4 import BeautifulSoup
from html import unescape

# What are we gonna do?
"""
1. Go through the folder of images to collect all the URLs - this will be an ordered list
2. Update html_dict to get first and last comic links
3. Construct 54 html pages for the comics lol
"""

base_dir = "/comics/hewligg_urobokkle"

# A dict containing all html elements for the comic pages to help construct the page
html_dict = {
    "first": """<a href="[REPLACE WITH LINK]">
                    <img src="/comics/navigation/first.png" alt="First Comic" />
                </a>""",
    "previous": """<a href="[REPLACE WITH LINK]">
                    <img src="/comics/navigation/previous.png" alt="Previous Comic" />
                </a>""",
    "next": """<a href="[REPLACE WITH LINK]">
                    <img src="/comics/navigation/next.png" alt="Next Comic" />
                </a>""",
    "last": """<a href="[REPLACE WITH LINK]">
                    <img src="/comics/navigation/last.png" alt="Last Comic" />
                </a>""",
}

# A dict with the first and last comics
links_dict = {
    "first": "",
    "last": "",
}


def get_comic_data():
    """Find comic_data.json and return it as a list of dictionaries"""
    # We start in the root of the repository so we need to go to the comics directory
    comics_dir = os.path.join("comics", "hewligg_urobokkle")

    # Get the list of files in the directory
    files = os.listdir(comics_dir)

    # Remove the 'pages' directory
    files.remove("pages")

    # They need sorting by number rather than alphabetically
    files = sorted(files, key=lambda x: float(x.replace(".PNG", "").replace("_", ".")))

    # Make sure it's sorted
    return files


def set_comic_links(data):
    """Update dictionaries with links to the first and last comics"""
    # The first element in the list is the first comic
    # The last element in the list is the last comic
    # (obviously)
    # Since this is an archive I will just hard code the links
    links_dict["first"] = "/comics/hewligg_urobokkle/pages/comic_1.html"
    links_dict["last"] = f"/comics/hewligg_urobokkle/pages/comic_54.html"

    # We can update the html_dict
    html_dict["first"] = html_dict["first"].replace(
        "[REPLACE WITH LINK]", links_dict["first"]
    )
    html_dict["last"] = html_dict["last"].replace(
        "[REPLACE WITH LINK]", links_dict["last"]
    )


def parse_comics(data):
    # This will loop through the comics and create the html for each one
    first = True
    last = False
    num_comics = 54
    comic_num = 1

    previous_link = ""
    next_link = f"{base_dir}/pages/comic_2.html"

    for comic in data:
        # Construct the navigation buttons
        nav = ""
        if not first:
            nav += html_dict["first"]
            nav += html_dict["previous"].replace("[REPLACE WITH LINK]", previous_link)
        if not last:
            nav += html_dict["next"].replace("[REPLACE WITH LINK]", next_link)
            nav += html_dict["last"]

        # Construct the html
        # Load the boilerplate
        html = ""
        with open("tools/comicBoilerplate.html", "r") as f:
            html = f.read()

        # Replace the title
        html = html.replace("[REPLACE WITH TITLE]", f"Hewligg Urobokkle - {comic_num}")

        # Delete the date
        html = html.replace("<h3>[REPLACE WITH DATE]</h3>", "")

        # Replace image
        html = html.replace("[REPLACE WITH IMAGE]", f"{base_dir}/{comic}")

        # Replace description
        html = html.replace("<p>[REPLACE WITH DESCRIPTION]</p>", "")

        # Replace navigation
        html = html.replace("[REPLACE WITH NAV]", nav)

        # Delete open graph tags
        html = html.replace("[REPLACE WITH OG]", "")

        # We've also got to swap "Pixelated Peculiarities" for "Hewligg Urobokkle"
        html = html.replace("Pixelated Peculiarities", "Hewligg Urobokkle")

        # Also no tooltip so get rid of this:
        html = html.replace('title="[REPLACE WITH TOOLTIP]"', "")

        # Write the html to a file in the comics directory
        with open(f"{base_dir[1:]}/pages/comic_{comic_num}.html", "w") as f:
            f.write(html)

        # Update links
        previous_link = f"{base_dir}/pages/comic_{comic_num}.html"
        next_link = f"{base_dir}/pages/comic_{comic_num + 2}.html"

        first = False
        comic_num += 1
        if comic_num == num_comics:
            last = True

        print(f"Created page for comic {comic_num - 1} of {num_comics}")


data = get_comic_data()
set_comic_links(data)
parse_comics(data)
